{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from src import graphconv\n",
    "from src import gcw\n",
    "from src import processtools as pt\n",
    "from src import healpyfunctional as hpf\n",
    "\n",
    "import healpy as hp\n",
    "\n",
    "from pygsp.graphs import SphereHealpix\n",
    "from pygsp import filters\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(tf.config.get_visible_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNHealpy_uNetlike(Model, gcw.GCW):\n",
    "    \"\"\"\n",
    "    Graph convolutional NN models for the healpy pixelization scheme. \n",
    "    Precalculates the polynomial approximation of the graph laplacian for graph convolutional layers.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 nside,\n",
    "                 indices,\n",
    "                 channels=1,\n",
    "                 use_polyK=False,\n",
    "                 verbose=True):\n",
    "        \"\"\"\n",
    "        :param nside: nside of the input maps\n",
    "        :param indices: indices of the input maps\n",
    "        :param channels: number of input channels\n",
    "        :param use_polyK: Bool. Optional. If True, will precalculate P(L) and use P(L) in graph convolution\n",
    "                          layers. Might lead to performance gains.\n",
    "        \"\"\"\n",
    "        super(GCNHealpy_uNetlike, self).__init__(name='')\n",
    "        self.nside = nside\n",
    "        self.indices = indices\n",
    "        self.channels = channels\n",
    "        self.use_polyK = use_polyK\n",
    "        self.verbose = verbose\n",
    "        self.polydict = {}\n",
    "        self.Ldict = {}\n",
    "    \n",
    "    def l2(self, weight_decay):\n",
    "        return tf.keras.regularizers.L2(l2=weight_decay)\n",
    "        \n",
    "    def model(self, weight_decay, sdrate, include_top=True, num_classes=3):\n",
    "        \"\"\"\n",
    "        :param weight_decay: l2 regularization penalty to apply on the convolution kernels\n",
    "        :param sdrate: spatial dropout rate to apply after the convolution layers\n",
    "        :param include_top: if true, will include the globalavereagepooling and densely connected layers\n",
    "        :param num_classes: number of outputs of the final densely connected layer.\n",
    "        \"\"\"\n",
    "        inputs = tf.keras.layers.Input(shape=(len(self.indices), self.channels), name=\"input_maps\")\n",
    "        x1 = self.Conv(nside=self.nside, indices=self.indices, n_neighbors=8, poly_type='chebyshev',\n",
    "                       K=4, Fout=16, activation='relu', use_bn=True, \n",
    "                       kernel_initializer='he_normal', kernel_regularizer=self.l2(weight_decay))(inputs)\n",
    "        x1 = self.Conv(nside=self.nside, indices=self.indices, n_neighbors=8, poly_type='chebyshev',\n",
    "                       K=4, Fout=16, activation='relu', use_bn=True, \n",
    "                       kernel_initializer='he_normal', kernel_regularizer=self.l2(weight_decay))(x1)\n",
    "        x1 = hpf.HealpyPseudoConv(p=1, Fout=16, activation='relu', initializer='he_normal',\n",
    "                                  kernel_regularizer=self.l2(weight_decay), nside=self.nside, \n",
    "                                  indices=self.indices)(x1)\n",
    "        x1 = tf.keras.layers.SpatialDropout1D(sdrate)(x1)        \n",
    "        x1 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                epsilon=0.001, center=False, \n",
    "                                                scale=False)(x1) \n",
    "\n",
    "        \n",
    "        x2 = self.Conv(nside=self.nside, indices=self.indices, n_neighbors=20, poly_type='chebyshev',\n",
    "                       K=8, Fout=32, activation='relu', use_bn=True, \n",
    "                       kernel_initializer='he_normal', kernel_regularizer=self.l2(weight_decay))(inputs)\n",
    "        x2 = hpf.HealpyPseudoConv(p=1, Fout=32, activation='relu', initializer='he_normal',\n",
    "                                  kernel_regularizer=self.l2(weight_decay), nside=self.nside, \n",
    "                                  indices=self.indices)(x2)\n",
    "        x2 = tf.keras.layers.SpatialDropout1D(sdrate)(x2)\n",
    "        x2 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                epsilon=0.001, center=False, \n",
    "                                                scale=False)(x2)\n",
    "        \n",
    "        x3 = self.Conv(nside=self.nside, indices=self.indices, n_neighbors=20, poly_type='chebyshev',\n",
    "                       K=12, Fout=16, activation='relu', use_bn=True, \n",
    "                       kernel_initializer='he_normal', kernel_regularizer=self.l2(weight_decay))(inputs)\n",
    "        x3 = hpf.HealpyPseudoConv(p=1, Fout=16, activation='relu', initializer='he_normal',\n",
    "                                  kernel_regularizer=self.l2(weight_decay), nside=self.nside, \n",
    "                                  indices=self.indices)(x3)\n",
    "        x3 = tf.keras.layers.SpatialDropout1D(sdrate)(x3)\n",
    "        x3 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                epsilon=0.001, center=False, \n",
    "                                                scale=False)(x3) \n",
    "\n",
    "        \n",
    "        nside_out1 = hpf.HealpyPseudoConv(p=1, Fout=16, activation='relu', \n",
    "                                          initializer='he_normal',\n",
    "                                          kernel_regularizer=self.l2(weight_decay),\n",
    "                                          nside=self.nside, indices=self.indices).nside_out\n",
    "        indices_out1 = hpf.HealpyPseudoConv(p=1, Fout=16, activation='relu', \n",
    "                                            initializer='he_normal',\n",
    "                                            kernel_regularizer=self.l2(weight_decay),\n",
    "                                            nside=self.nside, indices=self.indices).indices_out\n",
    "        \n",
    "        x = tf.keras.layers.Concatenate(axis=-1)([x1,x2,x3]) #output of 'conv+P 1', nside = 64, F=64\n",
    "\n",
    "        \n",
    "        x1 = self.Conv(nside=nside_out1, indices=indices_out1, n_neighbors=20, poly_type='chebyshev',\n",
    "                       K=4, Fout=32, activation='relu', use_bn=True, \n",
    "                       kernel_initializer='he_normal', kernel_regularizer=self.l2(weight_decay))(x)\n",
    "        x1 = self.Conv(nside=nside_out1, indices=indices_out1, n_neighbors=8, poly_type='chebyshev',\n",
    "                       K=8, Fout=32, activation='relu', use_bn=True, \n",
    "                       kernel_initializer='he_normal', kernel_regularizer=self.l2(weight_decay))(x1)\n",
    "        x1 = hpf.HealpyPseudoConv(p=1, Fout=32, activation='relu', \n",
    "                                  initializer='he_normal', kernel_regularizer=self.l2(weight_decay), \n",
    "                                  nside=nside_out1, indices=indices_out1)(x1)\n",
    "        x1 = tf.keras.layers.SpatialDropout1D(sdrate)(x1)\n",
    "        x1 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                epsilon=0.001, center=False, \n",
    "                                                scale=False)(x1) \n",
    "\n",
    "        \n",
    "        x2 = self.Conv(nside=nside_out1, indices=indices_out1, n_neighbors=20, poly_type='chebyshev',\n",
    "                       K=12, Fout=32, activation='relu', use_bn=True, \n",
    "                       kernel_initializer='he_normal', kernel_regularizer=self.l2(weight_decay))(x)\n",
    "        x2 = hpf.HealpyPseudoConv(p=1, Fout=32, activation='relu', \n",
    "                                  initializer='he_normal', kernel_regularizer=self.l2(weight_decay), \n",
    "                                  nside=nside_out1, indices=indices_out1)(x2)\n",
    "        x2 = tf.keras.layers.SpatialDropout1D(sdrate)(x2)\n",
    "        x2 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                epsilon=0.001, center=False, \n",
    "                                                scale=False)(x2) \n",
    "\n",
    "        \n",
    "        x3 = tf.keras.layers.Concatenate(axis=-1)([x1,x2])\n",
    "        \n",
    "        xres = hpf.HealpyPool(nside=nside_out1, indices = indices_out1, p=1, pool_type='AVG')(x)\n",
    "        xres = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                  epsilon=0.001, center=False, \n",
    "                                                  scale=False)(xres)        \n",
    "\n",
    "        nside_out2 = hpf.HealpyPool(nside=nside_out1, indices = indices_out1, \n",
    "                                    p=1, pool_type='AVG').nside_out\n",
    "        indices_out2 = hpf.HealpyPool(nside=nside_out1, indices = indices_out1, \n",
    "                                      p=1, pool_type='AVG').indices_out\n",
    "        \n",
    "        x = tf.keras.layers.Add()([x3,xres]) #output of 'conv+P 2', nside=32, F=128\n",
    "        \n",
    "        x1 = self.Conv(nside=nside_out2, indices=indices_out2, n_neighbors=8, poly_type='chebyshev',\n",
    "                      K=8, Fout=128, activation='relu', use_bn=True, \n",
    "                      kernel_initializer='he_normal', kernel_regularizer=self.l2(weight_decay))(x)\n",
    "        x = self.Conv(nside=nside_out2, indices=indices_out2, n_neighbors=20, poly_type='chebyshev',\n",
    "                      K=12, Fout=128, activation='relu', use_bn=True, \n",
    "                      kernel_initializer='he_normal', kernel_regularizer=self.l2(weight_decay))(x1)\n",
    "        \n",
    "        x1 = self.Conv(nside=nside_out2, indices=indices_out2, n_neighbors=8, poly_type='chebyshev',\n",
    "                      K=4, Fout=128, activation='relu', use_bn=True, \n",
    "                      kernel_initializer='he_normal', kernel_regularizer=self.l2(weight_decay))(x)\n",
    "        x1 = self.Conv(nside=nside_out2, indices=indices_out2, n_neighbors=20, poly_type='chebyshev',\n",
    "                      K=8, Fout=128, activation='relu', use_bn=True, \n",
    "                      kernel_initializer='he_normal', kernel_regularizer=self.l2(weight_decay))(x1)\n",
    "        \n",
    "        x = tf.keras.layers.Add()([x,x1]) #output of 'conv 3', nside = 32, F=128\n",
    "        \n",
    "        xup = hpf.HealpyPseudoConv_Transpose(nside=nside_out2, indices=indices_out2, \n",
    "                                             p=1, Fout=64, \n",
    "                                             kernel_initializer='he_normal')(x)\n",
    "        xup = tf.keras.layers.ReLU()(xup)\n",
    "        xup = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                 epsilon=0.001, center=False, \n",
    "                                                 scale=False)(xup)\n",
    "        \n",
    "        nside_up1 = hpf.HealpyPseudoConv_Transpose(nside=nside_out2, indices=indices_out2, \n",
    "                                                   p=1, Fout=64, \n",
    "                                                   kernel_initializer='he_normal').nside_out\n",
    "        indices_up1 = hpf.HealpyPseudoConv_Transpose(nside=nside_out2, indices=indices_out2, \n",
    "                                                   p=1, Fout=64, \n",
    "                                                   kernel_initializer='he_normal').indices_out\n",
    "        xup = self.Conv(nside=nside_up1, indices=indices_up1, n_neighbors=20, poly_type='chebyshev',\n",
    "                        K=8, Fout=64, activation='relu', use_bn=True, \n",
    "                        kernel_initializer='he_normal', kernel_regularizer=self.l2(weight_decay))(xup)\n",
    "        xup = hpf.HealpyPseudoConv(p=1, Fout=128, activation='relu', \n",
    "                                   initializer='he_normal', kernel_regularizer=self.l2(weight_decay), \n",
    "                                   nside=nside_out1, indices=indices_out1)(xup)\n",
    "        xup = tf.keras.layers.SpatialDropout1D(sdrate)(xup)\n",
    "        xup = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                 epsilon=0.001, center=False, \n",
    "                                                 scale=False)(xup) #output of 'u/d 1', nside=32, F=128\n",
    "        \n",
    "        \n",
    "        for i in range(2):\n",
    "            x1 = self.SeparableConv(nside=nside_out2,\n",
    "                                    indices=indices_out2,\n",
    "                                    n_neighbors=8,\n",
    "                                    poly_type='chebyshev',\n",
    "                                    K=6,\n",
    "                                    Fout=128,\n",
    "                                    depth_multiplier=2,\n",
    "                                    pointwise_initializer='he_normal',\n",
    "                                    depthwise_initializer='he_normal',\n",
    "                                    pointwise_regularizer=self.l2(weight_decay),\n",
    "                                    depthwise_regularizer=self.l2(weight_decay))(x)\n",
    "            x1 = tf.keras.layers.ReLU()(x1)\n",
    "            x1 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                    epsilon=0.001, center=False, \n",
    "                                                    scale=False)(x1)\n",
    "\n",
    "            \n",
    "            x1 = self.SeparableConv(nside=nside_out2,\n",
    "                                    indices=indices_out2,\n",
    "                                    n_neighbors=20,\n",
    "                                    poly_type='chebyshev',\n",
    "                                    K=10,\n",
    "                                    Fout=128,\n",
    "                                    depth_multiplier=2,\n",
    "                                    pointwise_initializer='he_normal',\n",
    "                                    depthwise_initializer='he_normal',\n",
    "                                    pointwise_regularizer=self.l2(weight_decay),\n",
    "                                    depthwise_regularizer=self.l2(weight_decay))(x1)\n",
    "            x1 = tf.keras.layers.ReLU()(x1)\n",
    "            x1 = tf.keras.layers.SpatialDropout1D(sdrate)(x1)            \n",
    "            x1 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                    epsilon=0.001, center=False, \n",
    "                                                    scale=False)(x1)         \n",
    "        \n",
    "            x = tf.keras.layers.Add()([x, x1]) #output of 'sepconv 1', nside=32, F=128\n",
    "            \n",
    "        x = tf.keras.layers.Add()([x, xup])\n",
    "        \n",
    "        x = self.DepthwiseConv(nside=nside_out2, indices=indices_out2, n_neighbors=20, poly_type='chebyshev',\n",
    "                      K=8, depth_multiplier=2, activation='relu', use_bn=True, \n",
    "                      kernel_initializer='he_normal', kernel_regularizer=self.l2(weight_decay))(x)\n",
    "        x = hpf.HealpyPool(nside=nside_out2, indices=indices_out2, p=1, pool_type='AVG')(x)\n",
    "        x = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                               epsilon=0.001, center=False, \n",
    "                                               scale=False)(x)\n",
    "        x = tf.keras.layers.SpatialDropout1D(sdrate)(x) #output of 'dconv + P 1', nside=16, F=256\n",
    "        \n",
    "        nside_out3 = hpf.HealpyPool(nside=nside_out2, indices=indices_out2, p=1, pool_type='AVG').nside_out\n",
    "        indices_out3 = hpf.HealpyPool(nside=nside_out2, indices=indices_out2, p=1, pool_type='AVG').indices_out\n",
    "        \n",
    "        xup2 = hpf.HealpyPseudoConv_Transpose(nside=nside_out3, indices=indices_out3, \n",
    "                                             p=1, Fout=128, \n",
    "                                             kernel_initializer='he_normal')(x)\n",
    "        xup2 = tf.keras.layers.ReLU()(xup2)\n",
    "        xup2 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                 epsilon=0.001, center=False, \n",
    "                                                 scale=False)(xup2)\n",
    "        \n",
    "        nside_up2 = hpf.HealpyPseudoConv_Transpose(nside=nside_out3, indices=indices_out3, \n",
    "                                                   p=1, Fout=128, \n",
    "                                                   kernel_initializer='he_normal').nside_out\n",
    "        indices_up2 = hpf.HealpyPseudoConv_Transpose(nside=nside_out3, indices=indices_out3, \n",
    "                                                   p=1, Fout=128, \n",
    "                                                   kernel_initializer='he_normal').indices_out\n",
    "        \n",
    "        xupmasked = hpf.HealpyMask(unmasked_indices=indices_up2)(xup)\n",
    "        xup2 = tf.keras.layers.Add()([xupmasked, xup2])\n",
    "\n",
    "        xup2 = self.Conv(nside=nside_up2, indices=indices_up2, n_neighbors=20, poly_type='chebyshev',\n",
    "                        K=8, Fout=128, activation='relu', use_bn=True, \n",
    "                        kernel_initializer='he_normal', kernel_regularizer=self.l2(weight_decay))(xup2)\n",
    "        xup2 = hpf.HealpyPseudoConv(p=1, Fout=256, activation='relu', \n",
    "                                   initializer='he_normal', kernel_regularizer=self.l2(weight_decay), \n",
    "                                   nside=nside_up2, indices=indices_up2)(xup2)\n",
    "        xup2 = tf.keras.layers.SpatialDropout1D(sdrate)(xup2)\n",
    "        xup2 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                 epsilon=0.001, center=False, \n",
    "                                                 scale=False)(xup2) #output of 'u/d 2', nside=16, F=256\n",
    "        \n",
    "        for i in range(2):\n",
    "            x1 = self.SeparableConv(nside=nside_out3,\n",
    "                                    indices=indices_out3,\n",
    "                                    n_neighbors=20,\n",
    "                                    poly_type='chebyshev',\n",
    "                                    K=4,\n",
    "                                    Fout=256,\n",
    "                                    depth_multiplier=1,\n",
    "                                    pointwise_initializer='he_normal',\n",
    "                                    depthwise_initializer='he_normal',\n",
    "                                    pointwise_regularizer=self.l2(weight_decay),\n",
    "                                    depthwise_regularizer=self.l2(weight_decay))(x)\n",
    "            x1 = tf.keras.layers.ReLU()(x1)            \n",
    "            x1 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                    epsilon=0.001, center=False, \n",
    "                                                    scale=False)(x1)\n",
    "\n",
    "            \n",
    "            x1 = self.SeparableConv(nside=nside_out3,\n",
    "                                    indices=indices_out3,\n",
    "                                    n_neighbors=8,\n",
    "                                    poly_type='chebyshev',\n",
    "                                    K=8,\n",
    "                                    Fout=256,\n",
    "                                    depth_multiplier=1,\n",
    "                                    pointwise_initializer='he_normal',\n",
    "                                    depthwise_initializer='he_normal',\n",
    "                                    pointwise_regularizer=self.l2(weight_decay),\n",
    "                                    depthwise_regularizer=self.l2(weight_decay))(x1)\n",
    "            x1 = tf.keras.layers.ReLU()(x1)   \n",
    "            x1 = tf.keras.layers.SpatialDropout1D(sdrate)(x1)            \n",
    "            x1 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                    epsilon=0.001, center=False, \n",
    "                                                    scale=False)(x1)\n",
    "         \n",
    "        \n",
    "            x = tf.keras.layers.Add()([x, x1])  #output of 'sepconv 2', nside=16, F=256\n",
    "            \n",
    "        x = tf.keras.layers.Add()([x, xup2])\n",
    "        \n",
    "        x = self.Conv(nside=nside_out3, indices=indices_out3, n_neighbors=8, poly_type='chebyshev',\n",
    "                      K=8, Fout=512, activation='relu', use_bn=True, \n",
    "                      kernel_regularizer=self.l2(weight_decay))(x)\n",
    "        x = hpf.HealpyPool(nside=nside_out3, indices=indices_out3, p=1, pool_type='AVG')(x)\n",
    "        x = tf.keras.layers.SpatialDropout1D(sdrate)(x)\n",
    "        x = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                               epsilon=0.001, center=False, \n",
    "                                               scale=False)(x) #output of 'conv+P 3', nside=8, F=512\n",
    "        \n",
    "        nside_out4 = hpf.HealpyPool(nside=nside_out3, indices=indices_out3, p=1, pool_type='AVG').nside_out\n",
    "        indices_out4 = hpf.HealpyPool(nside=nside_out3, indices=indices_out3, p=1, pool_type='AVG').indices_out\n",
    "        \n",
    "        xup3 = hpf.HealpyPseudoConv_Transpose(nside=nside_out4, indices=indices_out4, \n",
    "                                             p=1, Fout=256, \n",
    "                                             kernel_initializer='he_normal')(x)\n",
    "        xup3 = tf.keras.layers.ReLU()(xup3)\n",
    "        xup3 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                 epsilon=0.001, center=False, \n",
    "                                                 scale=False)(xup3)\n",
    "        \n",
    "        nside_up3 = hpf.HealpyPseudoConv_Transpose(nside=nside_out4, indices=indices_out4, \n",
    "                                                   p=1, Fout=256, \n",
    "                                                   kernel_initializer='he_normal').nside_out\n",
    "        indices_up3 = hpf.HealpyPseudoConv_Transpose(nside=nside_out4, indices=indices_out4, \n",
    "                                                   p=1, Fout=256, \n",
    "                                                   kernel_initializer='he_normal').indices_out\n",
    "        \n",
    "        xup2masked = hpf.HealpyMask(unmasked_indices=indices_up3)(xup2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        xup3 = tf.keras.layers.Add()([xup2masked, xup3])\n",
    "\n",
    "        xup3 = self.Conv(nside=nside_up3, indices=indices_up3, n_neighbors=20, poly_type='chebyshev',\n",
    "                        K=8, Fout=256, activation='relu', use_bn=True, \n",
    "                        kernel_initializer='he_normal', kernel_regularizer=self.l2(weight_decay))(xup3)\n",
    "        xup3 = hpf.HealpyPseudoConv(p=1, Fout=512, activation='relu', \n",
    "                                   initializer='he_normal', kernel_regularizer=self.l2(weight_decay), \n",
    "                                   nside=nside_up3, indices=indices_up3)(xup3)\n",
    "        xup3 = tf.keras.layers.SpatialDropout1D(sdrate)(xup3)\n",
    "        xup3 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                 epsilon=0.001, center=False, \n",
    "                                                 scale=False)(xup3) #output of 'u/d 3', nside=8, F=512        \n",
    "        \n",
    "        for i in range(2):\n",
    "            x1 = self.SeparableConv(nside=nside_out4,\n",
    "                                    indices=indices_out4,\n",
    "                                    n_neighbors=8,\n",
    "                                    poly_type='chebyshev',\n",
    "                                    K=8,\n",
    "                                    Fout=512,\n",
    "                                    depth_multiplier=1,\n",
    "                                    pointwise_initializer='he_normal',\n",
    "                                    depthwise_initializer='he_normal',\n",
    "                                    pointwise_regularizer=self.l2(weight_decay),\n",
    "                                    depthwise_regularizer=self.l2(weight_decay))(x)\n",
    "            x1 = tf.keras.layers.ReLU()(x1)\n",
    "            x1 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                    epsilon=0.001, center=False, \n",
    "                                                    scale=False)(x1)\n",
    "\n",
    "            \n",
    "            x1 = self.SeparableConv(nside=nside_out4,\n",
    "                                    indices=indices_out4,\n",
    "                                    n_neighbors=8,\n",
    "                                    poly_type='chebyshev',\n",
    "                                    K=8,\n",
    "                                    Fout=512,\n",
    "                                    depth_multiplier=1,\n",
    "                                    pointwise_initializer='he_normal',\n",
    "                                    depthwise_initializer='he_normal',\n",
    "                                    pointwise_regularizer=self.l2(weight_decay),\n",
    "                                    depthwise_regularizer=self.l2(weight_decay))(x1)\n",
    "            x1 = tf.keras.layers.ReLU()(x1) \n",
    "            x1 = tf.keras.layers.SpatialDropout1D(sdrate)(x1)            \n",
    "            x1 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                                    epsilon=0.001, center=False, \n",
    "                                                    scale=False)(x1)\n",
    "           \n",
    "        \n",
    "            x = tf.keras.layers.Add()([x, x1])  #output of 'sep conv 3', nside=8, F=512\n",
    "        \n",
    "            \n",
    "        x = tf.keras.layers.Add()([x, xup3])\n",
    "        \n",
    "        x = self.SeparableConv(nside=nside_out4,\n",
    "                               indices=indices_out4,\n",
    "                               n_neighbors=8,\n",
    "                               poly_type='chebyshev',\n",
    "                               K=8,\n",
    "                               Fout=768,\n",
    "                               depth_multiplier=1,\n",
    "                               pointwise_initializer='he_normal',\n",
    "                               depthwise_initializer='he_normal',\n",
    "                               pointwise_regularizer=self.l2(weight_decay),\n",
    "                               depthwise_regularizer=self.l2(weight_decay))(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                               epsilon=0.001, center=False, \n",
    "                                               scale=False)(x)\n",
    "\n",
    "        \n",
    "        \n",
    "        if include_top == True:\n",
    "            outputs = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "            outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(outputs)\n",
    "                               \n",
    "        \n",
    "        return Model(inputs = inputs, outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loading complete.\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "print('Loading data...')\n",
    "a_lm_triv = np.load('data/realizations_L_infty_lmax_250_num_1000.npy').astype(np.complex128)\n",
    "a_lm_torus1400 = np.load('data/realizations_L_1400_lmax_250_num_1000.npy').astype(np.complex128)\n",
    "a_lm_torus2800 = np.load('data/realizations_L_2800_lmax_250_num_1000.npy').astype(np.complex128)\n",
    "print('Data loading complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the mask and calculating relevant map indices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oxg34/.usr/local/python/3.8.6/lib/python3.8/site-packages/healpy/fitsfunc.py:368: UserWarning: If you are not specifying the input dtype and using the default np.float64 dtype of read_map(), please consider that it will change in a future version to None as to keep the same dtype of the input file: please explicitly set the dtype if it is important to you.\n",
      "  warnings.warn(\n",
      "/home/oxg34/.usr/local/python/3.8.6/lib/python3.8/site-packages/healpy/fitsfunc.py:391: UserWarning: NSIDE = 2048\n",
      "  warnings.warn(\"NSIDE = {0:d}\".format(nside))\n",
      "/home/oxg34/.usr/local/python/3.8.6/lib/python3.8/site-packages/healpy/fitsfunc.py:400: UserWarning: ORDERING = NESTED in fits file\n",
      "  warnings.warn(\"ORDERING = {0:s} in fits file\".format(ordering))\n",
      "/home/oxg34/.usr/local/python/3.8.6/lib/python3.8/site-packages/healpy/fitsfunc.py:426: UserWarning: No INDXSCHM keyword in header file : assume IMPLICIT\n",
      "  warnings.warn(\"No INDXSCHM keyword in header file : \" \"assume {}\".format(schm))\n",
      "/home/oxg34/.usr/local/python/3.8.6/lib/python3.8/site-packages/healpy/fitsfunc.py:428: UserWarning: INDXSCHM = IMPLICIT\n",
      "  warnings.warn(\"INDXSCHM = {0:s}\".format(schm))\n",
      "/home/oxg34/.usr/local/python/3.8.6/lib/python3.8/site-packages/healpy/fitsfunc.py:486: UserWarning: Ordering converted to RING\n",
      "  warnings.warn(\"Ordering converted to RING\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask preparation done.\n"
     ]
    }
   ],
   "source": [
    "#input indices and masking:\n",
    "print('Preparing the mask and calculating relevant map indices')\n",
    "nside = 128\n",
    "npix = hp.nside2npix(nside=nside)\n",
    "indices = np.arange(npix)\n",
    "mask=hp.read_map('data/masks/COM_Mask_CMB-common-Mask-Int_2048_R3.fits')\n",
    "print('Mask preparation done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant map indices are calculated.\n"
     ]
    }
   ],
   "source": [
    "#unmasked pixels:\n",
    "unmasked_pix = pt.get_indices(mask=mask, nside=nside, target_nside=nside)\n",
    "#aggresive masking: (extend the mask)\n",
    "worst_case_pix = pt.get_indices(mask=mask, nside=nside, target_nside=8)\n",
    "#adaptive masking: (reduce the indices minimally only if pooling is to occur)\n",
    "adaptive_case_pix = pt.get_indices(mask=mask, nside=nside, target_nside=nside//2) #//2 is not necessary.\n",
    "print('Relevant map indices are calculated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining TensorFlow distribution strategy.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "#setting some strategy will still work on single GPU.\n",
    "print('Defining TensorFlow distribution strategy.')\n",
    "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.NcclAllReduce(num_packs=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TensorFlow datasets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oxg34/.usr/local/python/3.8.6/lib/python3.8/site-packages/healpy/sphtfunc.py:822: UserWarning: Sigma is 0.000000 arcmin (0.000000 rad) \n",
      "  warnings.warn(\n",
      "/home/oxg34/.usr/local/python/3.8.6/lib/python3.8/site-packages/healpy/sphtfunc.py:827: UserWarning: -> fwhm is 0.000000 arcmin\n",
      "  warnings.warn(\n",
      "/home/oxg34/.usr/local/python/3.8.6/lib/python3.8/site-packages/healpy/sphtfunc.py:822: UserWarning: Sigma is 0.000000 arcmin (0.000000 rad) \n",
      "  warnings.warn(\n",
      "/home/oxg34/.usr/local/python/3.8.6/lib/python3.8/site-packages/healpy/sphtfunc.py:827: UserWarning: -> fwhm is 0.000000 arcmin\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print('Creating TensorFlow datasets.')\n",
    "BATCH_SIZE_PER_REPLICA = 5\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "#create datasets:\n",
    "train_data, test_data, x_eval, y_eval, x_alm_train, y_train = pt.create_dataset(a_lm_torus1400[0:100], \n",
    "                                                                         a_lm_torus2800[0:100], \n",
    "                                                                         a_lm_triv[0:100], \n",
    "                                                                         relevant_pix=adaptive_case_pix,\n",
    "                                                                         global_batch_size=GLOBAL_BATCH_SIZE,\n",
    "                                                                         trainperc=0.8,\n",
    "                                                                         evalperc=0.05,\n",
    "                                                                         strategy=strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating L\n",
      "L found, no need to calculate.\n",
      "Calculating L\n",
      "L found, no need to calculate.\n",
      "Calculating L\n",
      "Calculating L\n",
      "L found, no need to calculate.\n",
      "Calculating L\n",
      "Calculating L\n",
      "L found, no need to calculate.\n",
      "L found, no need to calculate.\n",
      "L found, no need to calculate.\n",
      "L found, no need to calculate.\n",
      "L found, no need to calculate.\n",
      "L found, no need to calculate.\n",
      "L found, no need to calculate.\n",
      "L found, no need to calculate.\n",
      "L found, no need to calculate.\n",
      "Calculating L\n",
      "Calculating L\n",
      "L found, no need to calculate.\n",
      "L found, no need to calculate.\n",
      "L found, no need to calculate.\n",
      "L found, no need to calculate.\n",
      "Calculating L\n",
      "L found, no need to calculate.\n",
      "L found, no need to calculate.\n",
      "L found, no need to calculate.\n",
      "L found, no need to calculate.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________________________________________________\n",
      " Layer (type)                     Output Shape           Param #      Connected to                       \n",
      "=========================================================================================================\n",
      " input_maps (InputLayer)          [(None, 150092, 1)]    0            []                                 \n",
      "                                                                                                         \n",
      " graph_conv (GraphConv)           (None, 150092, 16)     96           ['input_maps[0][0]']               \n",
      "                                                                                                         \n",
      " graph_conv_1 (GraphConv)         (None, 150092, 16)     1056         ['graph_conv[0][0]']               \n",
      "                                                                                                         \n",
      " graph_conv_2 (GraphConv)         (None, 150092, 32)     320          ['input_maps[0][0]']               \n",
      "                                                                                                         \n",
      " graph_conv_3 (GraphConv)         (None, 150092, 16)     224          ['input_maps[0][0]']               \n",
      "                                                                                                         \n",
      " healpy_pseudo_conv (HealpyPseudo  (None, 37523, 16)     1040         ['graph_conv_1[0][0]']             \n",
      " Conv)                                                                                                   \n",
      "                                                                                                         \n",
      " healpy_pseudo_conv_1 (HealpyPseu  (None, 37523, 32)     4128         ['graph_conv_2[0][0]']             \n",
      " doConv)                                                                                                 \n",
      "                                                                                                         \n",
      " healpy_pseudo_conv_2 (HealpyPseu  (None, 37523, 16)     1040         ['graph_conv_3[0][0]']             \n",
      " doConv)                                                                                                 \n",
      "                                                                                                         \n",
      " spatial_dropout1d (SpatialDropou  (None, 37523, 16)     0            ['healpy_pseudo_conv[0][0]']       \n",
      " t1D)                                                                                                    \n",
      "                                                                                                         \n",
      " spatial_dropout1d_1 (SpatialDrop  (None, 37523, 32)     0            ['healpy_pseudo_conv_1[0][0]']     \n",
      " out1D)                                                                                                  \n",
      "                                                                                                         \n",
      " spatial_dropout1d_2 (SpatialDrop  (None, 37523, 16)     0            ['healpy_pseudo_conv_2[0][0]']     \n",
      " out1D)                                                                                                  \n",
      "                                                                                                         \n",
      " batch_normalization_2 (BatchNorm  (None, 37523, 16)     32           ['spatial_dropout1d[0][0]']        \n",
      " alization)                                                                                              \n",
      "                                                                                                         \n",
      " batch_normalization_4 (BatchNorm  (None, 37523, 32)     64           ['spatial_dropout1d_1[0][0]']      \n",
      " alization)                                                                                              \n",
      "                                                                                                         \n",
      " batch_normalization_6 (BatchNorm  (None, 37523, 16)     32           ['spatial_dropout1d_2[0][0]']      \n",
      " alization)                                                                                              \n",
      "                                                                                                         \n",
      " concatenate (Concatenate)        (None, 37523, 64)      0            ['batch_normalization_2[0][0]',    \n",
      "                                                                       'batch_normalization_4[0][0]',    \n",
      "                                                                       'batch_normalization_6[0][0]']    \n",
      "                                                                                                         \n",
      " graph_conv_4 (GraphConv)         (None, 37523, 32)      8256         ['concatenate[0][0]']              \n",
      "                                                                                                         \n",
      " graph_conv_5 (GraphConv)         (None, 37523, 32)      8256         ['graph_conv_4[0][0]']             \n",
      "                                                                                                         \n",
      " graph_conv_6 (GraphConv)         (None, 37523, 32)      24640        ['concatenate[0][0]']              \n",
      "                                                                                                         \n",
      " healpy_pseudo_conv_5 (HealpyPseu  (None, 8837, 32)      4128         ['graph_conv_5[0][0]']             \n",
      " doConv)                                                                                                 \n",
      "                                                                                                         \n",
      " healpy_pseudo_conv_6 (HealpyPseu  (None, 8837, 32)      4128         ['graph_conv_6[0][0]']             \n",
      " doConv)                                                                                                 \n",
      "                                                                                                         \n",
      " spatial_dropout1d_3 (SpatialDrop  (None, 8837, 32)      0            ['healpy_pseudo_conv_5[0][0]']     \n",
      " out1D)                                                                                                  \n",
      "                                                                                                         \n",
      " spatial_dropout1d_4 (SpatialDrop  (None, 8837, 32)      0            ['healpy_pseudo_conv_6[0][0]']     \n",
      " out1D)                                                                                                  \n",
      "                                                                                                         \n",
      " batch_normalization_9 (BatchNorm  (None, 8837, 32)      64           ['spatial_dropout1d_3[0][0]']      \n",
      " alization)                                                                                              \n",
      "                                                                                                         \n",
      " batch_normalization_11 (BatchNor  (None, 8837, 32)      64           ['spatial_dropout1d_4[0][0]']      \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " healpy_pool (HealpyPool)         (None, 8837, 64)       0            ['concatenate[0][0]']              \n",
      "                                                                                                         \n",
      " concatenate_1 (Concatenate)      (None, 8837, 64)       0            ['batch_normalization_9[0][0]',    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                       'batch_normalization_11[0][0]']   \n",
      "                                                                                                         \n",
      " batch_normalization_12 (BatchNor  (None, 8837, 64)      128          ['healpy_pool[0][0]']              \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " add (Add)                        (None, 8837, 64)       0            ['concatenate_1[0][0]',            \n",
      "                                                                       'batch_normalization_12[0][0]']   \n",
      "                                                                                                         \n",
      " graph_conv_7 (GraphConv)         (None, 8837, 128)      65792        ['add[0][0]']                      \n",
      "                                                                                                         \n",
      " graph_conv_8 (GraphConv)         (None, 8837, 128)      196864       ['graph_conv_7[0][0]']             \n",
      "                                                                                                         \n",
      " graph_conv_9 (GraphConv)         (None, 8837, 128)      65792        ['graph_conv_8[0][0]']             \n",
      "                                                                                                         \n",
      " graph_conv_10 (GraphConv)        (None, 8837, 128)      131328       ['graph_conv_9[0][0]']             \n",
      "                                                                                                         \n",
      " add_1 (Add)                      (None, 8837, 128)      0            ['graph_conv_8[0][0]',             \n",
      "                                                                       'graph_conv_10[0][0]']            \n",
      "                                                                                                         \n",
      " graph_separable_conv (GraphSepar  (None, 8837, 128)     34304        ['add_1[0][0]']                    \n",
      " ableConv)                                                                                               \n",
      "                                                                                                         \n",
      " re_lu_1 (ReLU)                   (None, 8837, 128)      0            ['graph_separable_conv[0][0]']     \n",
      "                                                                                                         \n",
      " batch_normalization_20 (BatchNor  (None, 8837, 128)     256          ['re_lu_1[0][0]']                  \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " graph_separable_conv_1 (GraphSep  (None, 8837, 128)     35328        ['batch_normalization_20[0][0]']   \n",
      " arableConv)                                                                                             \n",
      "                                                                                                         \n",
      " re_lu_2 (ReLU)                   (None, 8837, 128)      0            ['graph_separable_conv_1[0][0]']   \n",
      "                                                                                                         \n",
      " spatial_dropout1d_6 (SpatialDrop  (None, 8837, 128)     0            ['re_lu_2[0][0]']                  \n",
      " out1D)                                                                                                  \n",
      "                                                                                                         \n",
      " batch_normalization_21 (BatchNor  (None, 8837, 128)     256          ['spatial_dropout1d_6[0][0]']      \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " add_2 (Add)                      (None, 8837, 128)      0            ['add_1[0][0]',                    \n",
      "                                                                       'batch_normalization_21[0][0]']   \n",
      "                                                                                                         \n",
      " graph_separable_conv_2 (GraphSep  (None, 8837, 128)     34304        ['add_2[0][0]']                    \n",
      " arableConv)                                                                                             \n",
      "                                                                                                         \n",
      " re_lu_3 (ReLU)                   (None, 8837, 128)      0            ['graph_separable_conv_2[0][0]']   \n",
      "                                                                                                         \n",
      " healpy_pseudo_conv__transpose (H  (None, 35348, 64)     32832        ['add_1[0][0]']                    \n",
      " ealpyPseudoConv_Transpose)                                                                              \n",
      "                                                                                                         \n",
      " batch_normalization_22 (BatchNor  (None, 8837, 128)     256          ['re_lu_3[0][0]']                  \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " re_lu (ReLU)                     (None, 35348, 64)      0            ['healpy_pseudo_conv__transpose[0][\n",
      "                                                                      0]']                               \n",
      "                                                                                                         \n",
      " graph_separable_conv_3 (GraphSep  (None, 8837, 128)     35328        ['batch_normalization_22[0][0]']   \n",
      " arableConv)                                                                                             \n",
      "                                                                                                         \n",
      " batch_normalization_17 (BatchNor  (None, 35348, 64)     128          ['re_lu[0][0]']                    \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " re_lu_4 (ReLU)                   (None, 8837, 128)      0            ['graph_separable_conv_3[0][0]']   \n",
      "                                                                                                         \n",
      " graph_conv_11 (GraphConv)        (None, 35348, 64)      32896        ['batch_normalization_17[0][0]']   \n",
      "                                                                                                         \n",
      " spatial_dropout1d_7 (SpatialDrop  (None, 8837, 128)     0            ['re_lu_4[0][0]']                  \n",
      " out1D)                                                                                                  \n",
      "                                                                                                         \n",
      " healpy_pseudo_conv_7 (HealpyPseu  (None, 8837, 128)     32896        ['graph_conv_11[0][0]']            \n",
      " doConv)                                                                                                 \n",
      "                                                                                                         \n",
      " batch_normalization_23 (BatchNor  (None, 8837, 128)     256          ['spatial_dropout1d_7[0][0]']      \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " spatial_dropout1d_5 (SpatialDrop  (None, 8837, 128)     0            ['healpy_pseudo_conv_7[0][0]']     \n",
      " out1D)                                                                                                  \n",
      "                                                                                                         \n",
      " add_3 (Add)                      (None, 8837, 128)      0            ['add_2[0][0]',                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                       'batch_normalization_23[0][0]']   \n",
      "                                                                                                         \n",
      " batch_normalization_19 (BatchNor  (None, 8837, 128)     256          ['spatial_dropout1d_5[0][0]']      \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " add_4 (Add)                      (None, 8837, 128)      0            ['add_3[0][0]',                    \n",
      "                                                                       'batch_normalization_19[0][0]']   \n",
      "                                                                                                         \n",
      " graph_depthwise_conv (GraphDepth  (None, 8837, 256)     2560         ['add_4[0][0]']                    \n",
      " wiseConv)                                                                                               \n",
      "                                                                                                         \n",
      " healpy_pool_3 (HealpyPool)       (None, 1894, 256)      0            ['graph_depthwise_conv[0][0]']     \n",
      "                                                                                                         \n",
      " batch_normalization_25 (BatchNor  (None, 1894, 256)     512          ['healpy_pool_3[0][0]']            \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " spatial_dropout1d_8 (SpatialDrop  (None, 1894, 256)     0            ['batch_normalization_25[0][0]']   \n",
      " out1D)                                                                                                  \n",
      "                                                                                                         \n",
      " graph_separable_conv_4 (GraphSep  (None, 1894, 256)     66560        ['spatial_dropout1d_8[0][0]']      \n",
      " arableConv)                                                                                             \n",
      "                                                                                                         \n",
      " re_lu_6 (ReLU)                   (None, 1894, 256)      0            ['graph_separable_conv_4[0][0]']   \n",
      "                                                                                                         \n",
      " batch_normalization_29 (BatchNor  (None, 1894, 256)     512          ['re_lu_6[0][0]']                  \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " graph_separable_conv_5 (GraphSep  (None, 1894, 256)     67584        ['batch_normalization_29[0][0]']   \n",
      " arableConv)                                                                                             \n",
      "                                                                                                         \n",
      " re_lu_7 (ReLU)                   (None, 1894, 256)      0            ['graph_separable_conv_5[0][0]']   \n",
      "                                                                                                         \n",
      " spatial_dropout1d_10 (SpatialDro  (None, 1894, 256)     0            ['re_lu_7[0][0]']                  \n",
      " pout1D)                                                                                                 \n",
      "                                                                                                         \n",
      " batch_normalization_30 (BatchNor  (None, 1894, 256)     512          ['spatial_dropout1d_10[0][0]']     \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " add_6 (Add)                      (None, 1894, 256)      0            ['spatial_dropout1d_8[0][0]',      \n",
      "                                                                       'batch_normalization_30[0][0]']   \n",
      "                                                                                                         \n",
      " graph_separable_conv_6 (GraphSep  (None, 1894, 256)     66560        ['add_6[0][0]']                    \n",
      " arableConv)                                                                                             \n",
      "                                                                                                         \n",
      " healpy_pseudo_conv__transpose_3   (None, 7576, 128)     131200       ['spatial_dropout1d_8[0][0]']      \n",
      " (HealpyPseudoConv_Transpose)                                                                            \n",
      "                                                                                                         \n",
      " re_lu_8 (ReLU)                   (None, 1894, 256)      0            ['graph_separable_conv_6[0][0]']   \n",
      "                                                                                                         \n",
      " re_lu_5 (ReLU)                   (None, 7576, 128)      0            ['healpy_pseudo_conv__transpose_3[0\n",
      "                                                                      ][0]']                             \n",
      "                                                                                                         \n",
      " batch_normalization_31 (BatchNor  (None, 1894, 256)     512          ['re_lu_8[0][0]']                  \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " healpy_mask (HealpyMask)         (None, 7576, 128)      0            ['batch_normalization_19[0][0]']   \n",
      "                                                                                                         \n",
      " batch_normalization_26 (BatchNor  (None, 7576, 128)     256          ['re_lu_5[0][0]']                  \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " graph_separable_conv_7 (GraphSep  (None, 1894, 256)     67584        ['batch_normalization_31[0][0]']   \n",
      " arableConv)                                                                                             \n",
      "                                                                                                         \n",
      " add_5 (Add)                      (None, 7576, 128)      0            ['healpy_mask[0][0]',              \n",
      "                                                                       'batch_normalization_26[0][0]']   \n",
      "                                                                                                         \n",
      " re_lu_9 (ReLU)                   (None, 1894, 256)      0            ['graph_separable_conv_7[0][0]']   \n",
      "                                                                                                         \n",
      " graph_conv_12 (GraphConv)        (None, 7576, 128)      131328       ['add_5[0][0]']                    \n",
      "                                                                                                         \n",
      " spatial_dropout1d_11 (SpatialDro  (None, 1894, 256)     0            ['re_lu_9[0][0]']                  \n",
      " pout1D)                                                                                                 \n",
      "                                                                                                         \n",
      " healpy_pseudo_conv_8 (HealpyPseu  (None, 1894, 256)     131328       ['graph_conv_12[0][0]']            \n",
      " doConv)                                                                                                 \n",
      "                                                                                                         \n",
      " batch_normalization_32 (BatchNor  (None, 1894, 256)     512          ['spatial_dropout1d_11[0][0]']     \n",
      " malization)                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                         \n",
      " spatial_dropout1d_9 (SpatialDrop  (None, 1894, 256)     0            ['healpy_pseudo_conv_8[0][0]']     \n",
      " out1D)                                                                                                  \n",
      "                                                                                                         \n",
      " add_7 (Add)                      (None, 1894, 256)      0            ['add_6[0][0]',                    \n",
      "                                                                       'batch_normalization_32[0][0]']   \n",
      "                                                                                                         \n",
      " batch_normalization_28 (BatchNor  (None, 1894, 256)     512          ['spatial_dropout1d_9[0][0]']      \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " add_8 (Add)                      (None, 1894, 256)      0            ['add_7[0][0]',                    \n",
      "                                                                       'batch_normalization_28[0][0]']   \n",
      "                                                                                                         \n",
      " graph_conv_13 (GraphConv)        (None, 1894, 512)      1049600      ['add_8[0][0]']                    \n",
      "                                                                                                         \n",
      " healpy_pool_6 (HealpyPool)       (None, 316, 512)       0            ['graph_conv_13[0][0]']            \n",
      "                                                                                                         \n",
      " spatial_dropout1d_12 (SpatialDro  (None, 316, 512)      0            ['healpy_pool_6[0][0]']            \n",
      " pout1D)                                                                                                 \n",
      "                                                                                                         \n",
      " batch_normalization_34 (BatchNor  (None, 316, 512)      1024         ['spatial_dropout1d_12[0][0]']     \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " graph_separable_conv_8 (GraphSep  (None, 316, 512)      266240       ['batch_normalization_34[0][0]']   \n",
      " arableConv)                                                                                             \n",
      "                                                                                                         \n",
      " re_lu_11 (ReLU)                  (None, 316, 512)       0            ['graph_separable_conv_8[0][0]']   \n",
      "                                                                                                         \n",
      " batch_normalization_38 (BatchNor  (None, 316, 512)      1024         ['re_lu_11[0][0]']                 \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " graph_separable_conv_9 (GraphSep  (None, 316, 512)      266240       ['batch_normalization_38[0][0]']   \n",
      " arableConv)                                                                                             \n",
      "                                                                                                         \n",
      " re_lu_12 (ReLU)                  (None, 316, 512)       0            ['graph_separable_conv_9[0][0]']   \n",
      "                                                                                                         \n",
      " spatial_dropout1d_14 (SpatialDro  (None, 316, 512)      0            ['re_lu_12[0][0]']                 \n",
      " pout1D)                                                                                                 \n",
      "                                                                                                         \n",
      " batch_normalization_39 (BatchNor  (None, 316, 512)      1024         ['spatial_dropout1d_14[0][0]']     \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " add_9 (Add)                      (None, 316, 512)       0            ['batch_normalization_34[0][0]',   \n",
      "                                                                       'batch_normalization_39[0][0]']   \n",
      "                                                                                                         \n",
      " graph_separable_conv_10 (GraphSe  (None, 316, 512)      266240       ['add_9[0][0]']                    \n",
      " parableConv)                                                                                            \n",
      "                                                                                                         \n",
      " re_lu_13 (ReLU)                  (None, 316, 512)       0            ['graph_separable_conv_10[0][0]']  \n",
      "                                                                                                         \n",
      " healpy_pseudo_conv__transpose_6   (None, 1264, 256)     524544       ['batch_normalization_34[0][0]']   \n",
      " (HealpyPseudoConv_Transpose)                                                                            \n",
      "                                                                                                         \n",
      " batch_normalization_40 (BatchNor  (None, 316, 512)      1024         ['re_lu_13[0][0]']                 \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " re_lu_10 (ReLU)                  (None, 1264, 256)      0            ['healpy_pseudo_conv__transpose_6[0\n",
      "                                                                      ][0]']                             \n",
      "                                                                                                         \n",
      " graph_separable_conv_11 (GraphSe  (None, 316, 512)      266240       ['batch_normalization_40[0][0]']   \n",
      " parableConv)                                                                                            \n",
      "                                                                                                         \n",
      " batch_normalization_35 (BatchNor  (None, 1264, 256)     512          ['re_lu_10[0][0]']                 \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " re_lu_14 (ReLU)                  (None, 316, 512)       0            ['graph_separable_conv_11[0][0]']  \n",
      "                                                                                                         \n",
      " graph_conv_14 (GraphConv)        (None, 1264, 256)      524800       ['batch_normalization_35[0][0]']   \n",
      "                                                                                                         \n",
      " spatial_dropout1d_15 (SpatialDro  (None, 316, 512)      0            ['re_lu_14[0][0]']                 \n",
      " pout1D)                                                                                                 \n",
      "                                                                                                         \n",
      " healpy_pseudo_conv_9 (HealpyPseu  (None, 316, 512)      524800       ['graph_conv_14[0][0]']            \n",
      " doConv)                                                                                                 \n",
      "                                                                                                         \n",
      " batch_normalization_41 (BatchNor  (None, 316, 512)      1024         ['spatial_dropout1d_15[0][0]']     \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " spatial_dropout1d_13 (SpatialDro  (None, 316, 512)      0            ['healpy_pseudo_conv_9[0][0]']     \n",
      " pout1D)                                                                                                 \n",
      "                                                                                                         \n",
      " add_10 (Add)                     (None, 316, 512)       0            ['add_9[0][0]',                    \n",
      "                                                                       'batch_normalization_41[0][0]']   \n",
      "                                                                                                         \n",
      " batch_normalization_37 (BatchNor  (None, 316, 512)      1024         ['spatial_dropout1d_13[0][0]']     \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " add_11 (Add)                     (None, 316, 512)       0            ['add_10[0][0]',                   \n",
      "                                                                       'batch_normalization_37[0][0]']   \n",
      "                                                                                                         \n",
      " graph_separable_conv_12 (GraphSe  (None, 316, 512)      266240       ['add_11[0][0]']                   \n",
      " parableConv)                                                                                            \n",
      "                                                                                                         \n",
      " re_lu_15 (ReLU)                  (None, 316, 512)       0            ['graph_separable_conv_12[0][0]']  \n",
      "                                                                                                         \n",
      " batch_normalization_42 (BatchNor  (None, 316, 512)      1024         ['re_lu_15[0][0]']                 \n",
      " malization)                                                                                             \n",
      "                                                                                                         \n",
      " global_average_pooling1d (Global  (None, 512)           0            ['batch_normalization_42[0][0]']   \n",
      " AveragePooling1D)                                                                                       \n",
      "                                                                                                         \n",
      " dense (Dense)                    (None, 3)              1539         ['global_average_pooling1d[0][0]'] \n",
      "                                                                                                         \n",
      "=========================================================================================================\n",
      "Total params: 5,388,963\n",
      "Trainable params: 5,372,355\n",
      "Non-trainable params: 16,608\n",
      "_________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "with strategy.scope():\n",
    "    GCN = GCNHealpy_uNetlike(nside=nside, \n",
    "                      indices=adaptive_case_pix, \n",
    "                      channels=1,\n",
    "                      use_polyK=False)\n",
    "    model = GCN.model(weight_decay=1e-4, \n",
    "                      sdrate=0.05, \n",
    "                      include_top=True,\n",
    "                      num_classes=3)\n",
    "model.summary(105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "#checkpoint_path = \"runs_2/training_3_class/SGDopt_xception_v3_L_precalc_adaptive_mask/cp-{epoch:04d}.ckpt\"\n",
    "#checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "#checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "def lr_decay(lr_init, epoch, num_batches, decay=0.998):\n",
    "    steps = epoch * BUFFER_SIZE//GLOBAL_BATCH_SIZE + num_batches\n",
    "    if epoch < 20:\n",
    "        return lr_init\n",
    "    else:\n",
    "        return lr_init* (decay)**(-20*BUFFER_SIZE//GLOBAL_BATCH_SIZE)*(decay)**(steps)\n",
    "    \n",
    "with strategy.scope():\n",
    "  # Set reduction to `none` so we can do the reduction afterwards and divide by\n",
    "  # global batch size.\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    def compute_loss(labels, predictions):\n",
    "        per_example_loss = loss_object(labels, predictions)\n",
    "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3,  #1e-3 with mom = 0.8 and decay = 0.998 is very stable\n",
    "                                        momentum = 0.8,\n",
    "                                        nesterov=False)     #but seems to stagnate (or run out of data)\n",
    "    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "\n",
    "\n",
    "def train_step(inputs):\n",
    "    samples, labels = inputs\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(samples, training=True)\n",
    "        loss = compute_loss(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_accuracy.update_state(labels, predictions)\n",
    "    return loss \n",
    "\n",
    "def test_step(inputs):\n",
    "    samples, labels = inputs\n",
    "\n",
    "    predictions = model(samples, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss.update_state(t_loss)\n",
    "    test_accuracy.update_state(labels, predictions)\n",
    "\n",
    "# `run` replicates the provided computation and runs it\n",
    "# with the distributed input.\n",
    "@tf.function()\n",
    "def distributed_train_step(dataset_inputs):\n",
    "    per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
    "                         axis=None)\n",
    "\n",
    "@tf.function()\n",
    "def distributed_test_step(dataset_inputs):\n",
    "    return strategy.run(test_step, args=(dataset_inputs,))\n",
    "\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "\n",
    "logs = {}\n",
    "\n",
    "BUFFER_SIZE = len(x_alm_train)\n",
    "\n",
    "\n",
    "EPOCHS = 100\n",
    "AUG_EPOCH = 50 #at the end of 50th, 100th etc epochs, we will rotate the training data randomly\n",
    "print(\"------------------------------------------------------\")\n",
    "print(f\"Starting Training, Epochs:{EPOCHS}, Augmentation Epochs:{EPOCHS//AUG_EPOCH}\")\n",
    "print(\"------------------------------------------------------\")\n",
    "for epoch in range(EPOCHS):\n",
    "    ### TRAIN LOOP ###\n",
    "    print(f\"Starting with Epoch {epoch + 1}/{EPOCHS}\", flush=True)\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0    \n",
    "    with tqdm(train_data, total=BUFFER_SIZE//GLOBAL_BATCH_SIZE) as pbar:\n",
    "        for x in pbar:\n",
    "            optimizer.learning_rate = lr_decay(5e-4, epoch, num_batches, 0.9995)\n",
    "            pbar.set_description(f\"Epoch {epoch +1}/{EPOCHS}\", refresh=True)\n",
    "            total_loss += distributed_train_step(x)\n",
    "            num_batches += 1\n",
    "            pbar.set_postfix({'train_loss': total_loss.numpy()/num_batches,\n",
    "                              'learning_rate': optimizer.learning_rate.numpy()}, refresh=True)\n",
    "            \n",
    "        train_loss = total_loss / num_batches\n",
    "\n",
    "    ### TEST LOOP ###\n",
    "        for x in test_data:\n",
    "            distributed_test_step(x)\n",
    "\n",
    "    template = (\"Epoch {}/{}, Training Loss: {:.5g}, Training Accuracy: {:.5g}, Test Loss: {:.5g}, \"\n",
    "                \"Test Accuracy: {:.5g}\")\n",
    "    print (template.format(epoch+1, EPOCHS,train_loss.numpy(),\n",
    "                             train_accuracy.result().numpy(), test_loss.result().numpy(),\n",
    "                             test_accuracy.result().numpy()))\n",
    "    train_loss.append(train_loss)\n",
    "    train_accuracy.append(train_accuracy.result())\n",
    "    test_loss.append(test_loss.result())\n",
    "    test_accuracy.append(test_accuracy.result())\n",
    "    \n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    ### DATASET ROTATION ###\n",
    "    if epoch > 0:\n",
    "        if (epoch)%AUG_EPOCH == 0:\n",
    "            print(f\"Augmentation Epoch {(epoch+1)//AUG_EPOCH}/{EPOCHS//AUG_EPOCH} \")\n",
    "            print('Rotating training dataset...')\n",
    "            train_data = pt.rotate_train_data(alm=x_alm_train, y_train=y_train, \n",
    "                                                  relevant_pix=adaptive_case_pix, \n",
    "                                                  global_batch_size=GLOBAL_BATCH_SIZE, \n",
    "                                                  strategy=strategy)\n",
    "            print('Rotation complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(1,EPOCHS+1)\n",
    "fig, axes = plt.subplots(2, figsize=(10, 10), sharex=True)\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(epochs, train_loss_xception_v2, label = 'Training')\n",
    "axes[0].plot(epochs, test_loss_xception_v2, '--', label = 'Validation')\n",
    "axes[0].grid(visible=True, axis='both')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('Training Metrics (Adaptive Masking)')\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(epochs, train_accuracy_xception_v2, label = 'Training')\n",
    "axes[1].plot(epochs, test_accuracy_xception_v2, '--', label = 'Validation')\n",
    "axes[1].grid(visible=True, axis='both')\n",
    "#axes[1].set_yscale('log')\n",
    "axes[1].legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
